## Conclusions and future perspectives

Genomics plays an important role in realizing the promise of personalized medicine, although not without significant challenges.
In this review, we discuss different molecular phenotypes, theoretical models, and computational approaches that offer various mechanistic views on how genetic variation leads to phenotypic changes.
To fully understand the molecular basis of human complex traits, it is essential to integrate diverse datasets and unravel the complex structures of biological networks.
Gene co-expression networks, represented as gene modules, have been successfully used across a variety of fields [@doi:10.1186/1471-2105-9-559; @doi:10.1016/bs.mie.2016.09.016; @doi:10.1186/s12920-018-0407-1].
Here, we review the main components of a gene module-based approach that leverages gene co-expression patterns learned from large transcriptomic datasets to integrate GWAS, TWAS, and drug-induced transcriptional profiles.
Drawing on modern theories of the genetic architecture of complex traits, we show that these approaches can prioritize core genes and create interpretable frameworks for drug repurposing.

Gene-gene interactions are a key component in the omnigenic model.
While the integration of gene modules with gene-trait associations and gene-drug data has been a valuable first step, it represents only a fraction of the complexity inherent in biological systems.
Biological networks extend far beyond these initial layers, involving intricate, multilayered systems such as histone modifications, transcription factor binding sites, *cis*-regulatory networks, and chromatin conformation—all of which contribute to the co-regulation of gene transcription.
Moreover, this complexity includes protein-protein interaction networks, which form the backbone of signaling pathways and facilitate the transmission of signals both within and between cells.
Additionally, metabolic networks influence enzyme activities and metabolite levels, propagating changes that affect numerous other molecules [@doi:10.1371/journal.pgen.1008519; @doi:10.1371/journal.pcbi.1008819].

Thus, incorporating multiple data modalities into gene module construction is a critical next step to capture this biological complexity more fully.
By integrating diverse types of omics data such as epigenomics, proteomics, metabolomics, and chromatin accessibility, gene modules can be refined to reflect not just co-expression patterns but also shared regulatory mechanisms and functional interactions.
For instance, combining transcriptomic data with chromatin immunoprecipitation sequencing (ChIP-seq) can identify transcription factors that regulate module genes, while integrating methylation profiles can reveal epigenetic modifications that influence gene expression within modules.
An example of this integrative approach is the quantitative omnigenic model (QOM) proposed by Ružičková et al. [@doi:10.1073/pnas.2402340121], which demonstrates the power of integrating genomic data with regulatory network information to predict gene expression levels more accurately.
By utilizing the topology of gene regulatory networks, the QOM captures both direct genetic effects (*cis* effects) and indirect effects propagated through the network (*trans* effects), leading to improved performance over traditional GWAS with fewer parameters [@doi:10.1073/pnas.2402340121].
Similarly, in the context of psychiatric disorders, integrating epigenetic data into the omnigenic model has been proposed to refine gene modules and enhance the understanding of the complex interplay between genetics and epigenetics in these conditions.
Evidence shows widespread epigenetic abnormalities, including DNA methylation changes across multiple brain regions in disorders such as schizophrenia, bipolar disorder, and major depressive disorder.
Peedicayil and Grayson discussed how incorporating epigenetic mechanisms, such as DNA methylation, histone modifications, and noncoding RNAs—into the omnigenic model could help explain the extensive genetic and epigenetic factors contributing to these disorders [@doi:10.1016/j.jtbi.2018.01.027].
Although this multimodal approach has not been widely exploited, it holds great promise for uncovering the underlying mechanisms of complex traits and diseases, aiming to create better predictive models.

A gene module approach that integrates genetic studies has several important components: 1) gene expression data relevant to the research problem, such as large heterogeneous datasets that span different conditions, or otherwise focused, smaller datasets that capture more subtle, unique, and disease-specific gene modules; 2) unbiased and relevant prior information that can be used during or after module extraction to distinguish relevant transcriptomic signatures from technical noise; and 3) reliable single variant/gene associations with the complex traits of interest.
Therefore, it is important to emphasize that a gene module approach is by no means a replacement for current single variant/gene approaches.
The development of new and improved statistical methods that detect more causal genes, regardless of whether they have a direct or indirect effect on the trait, while reducing false positives [@doi:10.1038/s41588-023-01648-9], will only enhance other approaches that rely on them, such as the gene module-based methods described here.
In this review, we demonstrate that the identification of peripheral genes is key to prioritizing core genes that might represent more attractive drug targets, strongly suggesting that the mechanism proposed by the omnigenic model—i.e., that gene regulatory networks are highly interconnected and genes have specific roles with more direct or indirect effects on traits—is useful.

As the demand for analyzing large datasets and uncovering complex biological patterns grows, the need for faster and more efficient computational methods becomes increasingly critical.
Future bioinformatics tools must not only handle the scale of these tasks but also ensure that they are accessible and adaptable across different computational environments.
To meet these challenges, we are focusing on accelerating workflows with graphics processing unit (GPU) technology and exploring new platforms, such as WebAssembly, to bring powerful tools directly to users' browsers.

Leveraging GPU acceleration holds great promise for significantly speeding up bioinformatics workflows.
Research has shown that GPU technology can provide remarkable performance boosts, with speed improvements reaching up to 1000x for specific tasks [@doi:10.1093/bib/bbw058].
Integrating GPU-aware libraries like CuPy [@Okuta2017] and RAPIDS [@url:https://rapids.ai] into our tools allows for seamless performance upgrades in established frameworks such as NumPy [@doi:10.1038/s41586-020-2649-2] and Scikit-learn [@doi:10.48550/arXiv.1201.0490].
As our tools evolve, we anticipate developing custom GPU kernels to further enhance speed and optimize them for specific computational needs.
Advanced GPU programming with PyCUDA [@doi:10.1016/j.parco.2011.09.001] could also be key to future optimizations.

Another promising direction is utilizing WebAssembly [@doi:10.1145/3062341.3062363] to make bioinformatics tools more portable and accessible.
We aim to adapt existing bioinformatics applications into web-based tools that can be run directly in the browser, providing users with full control over their data and eliminating the need for data transfer over networks.
Projects like Biowasm [@url:https://biowasm.com], Kana [@doi:10.1101/2022.03.02.482701], and VirtualWasm [@doi:10.1093/bioinformatics/btae018] have already demonstrated the potential of WebAssembly for genomics and single-cell analysis, and we plan to build on this foundation.
By executing statistical analyses, computations, and visualizations directly on the user's device, WebAssembly will not only address privacy and compliance concerns but also reduce server costs and computational load by shifting the workload to the client side.

Future innovations in GPU acceleration and WebAssembly will transform how bioinformatics tools are developed and deployed, leading to faster, more accessible solutions for researchers worldwide.
By integrating these technologies, we can build the next generation of computational platforms that combine speed, flexibility, and privacy, unlocking new potential for biological discoveries.
As these technologies mature, they will enable even more ambitious and large-scale analyses to be performed quickly and efficiently.
